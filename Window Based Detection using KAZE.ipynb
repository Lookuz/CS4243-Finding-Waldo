{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Window-Based Detection using KAZE Descriptor Featuring Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import metrics as sk_metrics\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import pickle as pkl\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import xgboost\n",
    "\n",
    "from dataset import *\n",
    "from descriptor import *\n",
    "from SlidingWindow import *\n",
    "from BagOfWords import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "run_sliding_window = False\n",
    "\n",
    "curr_wd = os.getcwd()\n",
    "example_path = os.path.join(curr_wd, 'datasets/', 'JPEGImages/', '004.jpg')\n",
    "example_full_path = os.path.join(curr_wd, 'datasets/', 'JPEGImages/', '000.jpg')\n",
    "train_annot_path = os.path.join(curr_wd, 'cache_anno/', 'train_annots.pkl')\n",
    "\n",
    "# Paths for training data\n",
    "goal_dir = os.path.join(curr_wd, 'datasets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding Window\n",
    "\n",
    "In order to perform window based detection on an image, we need to construct a sliding window subroutine in order to iterate over windows in an image. In the following demonstration, a multiscale sliding window routine using image pyramids is displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load example image \n",
    "example_image = plt.imread(example_path)\n",
    "plt.rcParams['figure.figsize'] = (5.0, 5.0)\n",
    "plt.imshow(example_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sliding window routine\n",
    "window_size = (100, 100)\n",
    "if run_sliding_window: # Toggle demo using this variable\n",
    "    for sub_image in image_pyramid(example_image, scale=1.5):\n",
    "        for coordinates, window in sliding_window(sub_image, step_size=100, window_size=window_size):\n",
    "            # NOTE: Can apply sub routine to process each image here\n",
    "\n",
    "            # Extract coordinates of current bounding box\n",
    "            y, x, y_end, x_end = coordinates\n",
    "\n",
    "            sub_image_copy = sub_image.copy() \n",
    "            cv2.rectangle(sub_image_copy, (x, y), (x_end, y_end), (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Example\", sub_image_copy)\n",
    "            cv2.waitKey(1)\n",
    "            time.sleep(0.025)\n",
    "\n",
    "# NOTE: Running this cell block may crash the kernel. Only do so to visualise the results of sliding window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset\n",
    "\n",
    "Loads the patches from the `datasets/train/positives` and `datasets/train/extra` as training data for classifier model. The patches are in the type `ndarray`\n",
    "<br> *detection calss allowed:* </br>\n",
    "<br> **waldo_face_front** </br>\n",
    "<br> **waldo_face_side** </br>\n",
    "<br> **waldo_body_full** </br>\n",
    "<br> **waldo_body_half** </br>\n",
    "<br> **wenda_face_front** </br>\n",
    "<br> **wenda_body_full** </br>\n",
    "<br> **wenda_body_half** </br>\n",
    "<br> **wizard_face_front** </br>\n",
    "<br> **wizard_body_full** </br>\n",
    "<br> **wizard_body_half** </br>\n",
    "<br> **other_face_front** </br>\n",
    "<br> **other_body_full** </br>\n",
    "<br> **other_body_half**</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "# here we focus on faces\n",
    "detection_class = ['waldo_face_front']\n",
    "train_loader, valid_loader = prepare_classification_dataloader(detection_class, simple=True, neg_ratio=0.2)\n",
    "train_instances, valid_instances = list(train_loader), list(valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12.0, 12.0)\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(train_instances[0][0])\n",
    "plt.axis('off')\n",
    "plt.title('Original Patch, ' + str(train_instances[0][1]))\n",
    "\n",
    "# Convert to RGB\n",
    "def to_rgb(img):\n",
    "    return img[:, :, ::-1]\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "valid_images = []\n",
    "valid_labels = []\n",
    "\n",
    "for img, gt in train_instances:\n",
    "    train_images.append(to_rgb(img))\n",
    "    train_labels.append(gt)\n",
    "    \n",
    "for img, gt in valid_instances:\n",
    "    valid_images.append(to_rgb(img))\n",
    "    valid_labels.append(gt)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(train_images[0])\n",
    "plt.axis('off')\n",
    "plt.title('RGB Converted, ' + str(train_labels[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract feature descriptors from training set\n",
    "train_features = extract_features(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster the keypoints to obtain features\n",
    "print('Number of KAZE descriptors:', len(train_features))\n",
    "bag_of_words = cluster_features(train_features) # Default number of clusters is 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_histograms = extract_histograms(train_images, bag_of_words)\n",
    "train_histograms, train_labels = shuffle(train_histograms, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Classifier\n",
    "\n",
    "After extracting the Bag Of Words from the training patches, we then train our classifer on the histogram vector features from training data patches, and test it on our validation patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the validation set\n",
    "print('Number of validation examples: ', len(valid_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_histograms = extract_histograms(valid_images, bag_of_words)\n",
    "valid_histograms, valid_labels = shuffle(valid_histograms, valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize classification model\n",
    "# SVM Model\n",
    "svm = SVC(kernel='rbf')\n",
    "svm.fit(train_histograms, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_predict = svm.predict(valid_histograms)\n",
    "print(valid_labels)\n",
    "precision = sk_metrics.precision_score(y_true=valid_labels, y_pred=valid_predict)\n",
    "recall = sk_metrics.recall_score(y_true=valid_labels, y_pred=valid_predict)\n",
    "f1_score = sk_metrics.f1_score(y_true=valid_labels, y_pred=valid_predict)\n",
    "print('Precision: %.3f\\nRecall: %.3f\\nF1 Score: %.3f' % (precision, recall, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost Model\n",
    "# NOTE: XGB requires heavy tuning \n",
    "xgb = xgboost.XGBClassifier(learning_rate=0.001, n_estimators=250, max_depth=5)\n",
    "xgb.fit(train_histograms, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predict = xgb.predict(val_histograms)\n",
    "precision = sk_metrics.precision_score(y_true=val_labels, y_pred=val_predict)\n",
    "recall = sk_metrics.recall_score(y_true=val_labels, y_pred=val_predict)\n",
    "f1_score = sk_metrics.f1_score(y_true=val_labels, y_pred=val_predict)\n",
    "print('Precision: %.3f\\nRecall: %.3f\\nF1 Score: %.3f' % (precision, recall, f1_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(train_histograms, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predict = rf.predict(val_histograms)\n",
    "precision = sk_metrics.precision_score(y_true=val_labels, y_pred=val_predict)\n",
    "recall = sk_metrics.recall_score(y_true=val_labels, y_pred=val_predict)\n",
    "f1_score = sk_metrics.f1_score(y_true=val_labels, y_pred=val_predict)\n",
    "print('Precision: %.3f\\nRecall: %.3f\\nF1 Score: %.3f' % (precision, recall, f1_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sliding Window Scoring\n",
    "\n",
    "We now use our trained classifer to score each window, and threshold windows that have scores beyond a certain benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise window on training image\n",
    "plt.rcParams['figure.figsize'] = (12.0, 12.0)\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "window_size = (200, 400)\n",
    "step_size = 500\n",
    "\n",
    "example_full = plt.imread(example_full_path)\n",
    "ax.imshow(example_full)\n",
    "\n",
    "rect = patches.Rectangle((4000, 3500), window_size[0], window_size[1], linewidth=2, edgecolor='b', facecolor='none')\n",
    "ax.add_patch(rect)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform detection\n",
    "detections = detect(example_full, bag_of_words, svm)\n",
    "print('Number of Bounding Boxes: ', len(detections))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise detections\n",
    "ground_truth = train_annots['000']['waldo']\n",
    "clone = example_full.copy()\n",
    "for (x1, y1, x2, y2) in detections:\n",
    "    cv2.rectangle(clone, (x1, y1), (x2, y2), (0, 0, 255), thickness=25)\n",
    "cv2.rectangle(clone, (ground_truth[0], ground_truth[1]), (ground_truth[2], ground_truth[3]), (0, 255, 0), thickness=25)\n",
    "plt.imshow(clone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
